Bayes_rule_for_x = prob_x_given_1 * pi_1 / (prob_x_given_1 * pi_1 + prob_x_given_0 * pi_0)
#Assign value to classifier
if(Bayes_rule_for_x>=1/2){
train_data$'new_Y'=1
}else {train_data$'new_Y'=0}
x_obs = train_data[17,1]
#prob_x_given_0
given0_density = density(train_data$X[train_data$Y==0])
given0_index = sum(given0_density$x <= x_obs)
prob_x_given_0 = given0_density$y[given0_index]
#prob_x_given_1
given1_density = density(train_data$X[train_data$Y==1])
given1_index = sum(given1_density$x <= x_obs)
prob_x_given_1 = given1_density$y[given1_index]
Bayes_rule_for_x = prob_x_given_1 * pi_1 / (prob_x_given_1 * pi_1 + prob_x_given_0 * pi_0)
#Assign value to classifier
if(Bayes_rule_for_x>=1/2){
train_data$'new_Y'=1
}else {train_data$'new_Y'=0}
x_obs = train_data[18,1]
#prob_x_given_0
given0_density = density(train_data$X[train_data$Y==0])
given0_index = sum(given0_density$x <= x_obs)
prob_x_given_0 = given0_density$y[given0_index]
#prob_x_given_1
given1_density = density(train_data$X[train_data$Y==1])
given1_index = sum(given1_density$x <= x_obs)
prob_x_given_1 = given1_density$y[given1_index]
Bayes_rule_for_x = prob_x_given_1 * pi_1 / (prob_x_given_1 * pi_1 + prob_x_given_0 * pi_0)
#Assign value to classifier
if(Bayes_rule_for_x>=1/2){
train_data$'new_Y'=1
}else {train_data$'new_Y'=0}
x_obs = train_data[17,1]
#prob_x_given_0
given0_density = density(train_data$X[train_data$Y==0])
given0_index = sum(given0_density$x <= x_obs)
prob_x_given_0 = given0_density$y[given0_index]
#prob_x_given_1
given1_density = density(train_data$X[train_data$Y==1])
given1_index = sum(given1_density$x <= x_obs)
prob_x_given_1 = given1_density$y[given1_index]
Bayes_rule_for_x = prob_x_given_1 * pi_1 / (prob_x_given_1 * pi_1 + prob_x_given_0 * pi_0)
#Assign value to classifier
if(Bayes_rule_for_x>=1/2){
train_data$'new_Y'=1
}else {train_data$'new_Y'=0}
size(Bayes_rule_for_x)
Bayes_rule_for_x
length(Bayes_rule_for_x)
for (i in 1:nrow(train_data)) {
x_obs = train_data[i,1]
#prob_x_given_0
given0_density = density(train_data$X[train_data$Y==0])
given0_index = sum(given0_density$x <= x_obs)
prob_x_given_0 = given0_density$y[given0_index]
#prob_x_given_1
given1_density = density(train_data$X[train_data$Y==1])
given1_index = sum(given1_density$x <= x_obs)
prob_x_given_1 = given1_density$y[given1_index]
Bayes_rule_for_x = prob_x_given_1 * pi_1 / (prob_x_given_1 * pi_1 + prob_x_given_0 * pi_0)
#Assign value to classifier
if(length(Bayes_rule_for_x)==0){
train_data$new_Y=0
}
else if(Bayes_rule_for_x>=1/2){
train_data$'new_Y'=1
}else {train_data$'new_Y'=0}
}
for (i in 1:nrow(train_data)) {
x_obs = train_data[i,1]
#prob_x_given_0
given0_density = density(train_data$X[train_data$Y==0])
given0_index = sum(given0_density$x <= x_obs)
prob_x_given_0 = given0_density$y[given0_index]
#prob_x_given_1
given1_density = density(train_data$X[train_data$Y==1])
given1_index = sum(given1_density$x <= x_obs)
prob_x_given_1 = given1_density$y[given1_index]
Bayes_rule_for_x = prob_x_given_1 * pi_1 / (prob_x_given_1 * pi_1 + prob_x_given_0 * pi_0)
#Assign value to classifier
if(length(Bayes_rule_for_x)==0){
train_data$new_Y=0
}
else if(Bayes_rule_for_x>=1/2){
train_data$'new_Y'=1
}else if(Bayes_rule_for_x<1/2){train_data$'new_Y'=0}
}
train_data$'new_Y' = NA
for (i in 1:nrow(train_data)) {
x_obs = train_data[i,1]
#prob_x_given_0
given0_density = density(train_data$X[train_data$Y==0])
given0_index = sum(given0_density$x <= x_obs)
prob_x_given_0 = given0_density$y[given0_index]
#prob_x_given_1
given1_density = density(train_data$X[train_data$Y==1])
given1_index = sum(given1_density$x <= x_obs)
prob_x_given_1 = given1_density$y[given1_index]
Bayes_rule_for_x = prob_x_given_1 * pi_1 / (prob_x_given_1 * pi_1 + prob_x_given_0 * pi_0)
#Assign value to classifier
if(length(Bayes_rule_for_x)==0){
train_data$`new_Y`=0
}
else if(Bayes_rule_for_x>=1/2){
train_data$'new_Y'=1
}else if(Bayes_rule_for_x<1/2){train_data$'new_Y'=0}
}
View(train_data)
train_data$'new_Y' = NA
for (i in 1:nrow(train_data)) {
x_obs = train_data[i,1]
#prob_x_given_0
given0_density = density(train_data$X[train_data$Y==0])
given0_index = sum(given0_density$x <= x_obs)
prob_x_given_0 = given0_density$y[given0_index]
#prob_x_given_1
given1_density = density(train_data$X[train_data$Y==1])
given1_index = sum(given1_density$x <= x_obs)
prob_x_given_1 = given1_density$y[given1_index]
Bayes_rule_for_x = prob_x_given_1 * pi_1 / (prob_x_given_1 * pi_1 + prob_x_given_0 * pi_0)
#Assign value to classifier
if(length(Bayes_rule_for_x)==0){
train_data$`new_Y`[i]=0
}
else if(Bayes_rule_for_x>=1/2){
train_data$'new_Y'[i]=1
}else if(Bayes_rule_for_x<1/2){train_data$'new_Y'[i]=0}
}
train_data$'new_Y' = NA
for (i in 1:nrow(train_data)) {
x_obs = train_data[i,1]
#prob_x_given_0
given0_density = density(train_data$X[train_data$Y==0])
given0_index = sum(given0_density$x <= x_obs)
prob_x_given_0 = given0_density$y[given0_index]
#prob_x_given_1
given1_density = density(train_data$X[train_data$Y==1])
given1_index = sum(given1_density$x <= x_obs)
prob_x_given_1 = given1_density$y[given1_index]
Bayes_rule_for_x = prob_x_given_1 * pi_1 / (prob_x_given_1 * pi_1 + prob_x_given_0 * pi_0)
#Assign value to classifier
# if(length(Bayes_rule_for_x)==0){
#  train_data$`new_Y`[i]=0
#}
#else
if(Bayes_rule_for_x>=1/2){
train_data$'new_Y'[i]=1
}else {train_data$'new_Y'[i]=0}
}
train_data$'new_Y' = NA
for (i in 1:nrow(train_data)) {
x_obs = train_data[i,1]
#prob_x_given_0
given0_density = density(train_data$X[train_data$Y==0])
given0_index = sum(given0_density$x <= x_obs)
prob_x_given_0 = given0_density$y[given0_index]
#prob_x_given_1
given1_density = density(train_data$X[train_data$Y==1])
given1_index = sum(given1_density$x <= x_obs)
prob_x_given_1 = given1_density$y[given1_index]
Bayes_rule_for_x = prob_x_given_1 * pi_1 / (prob_x_given_1 * pi_1 + prob_x_given_0 * pi_0)
#Assign value to classifier
if(length(Bayes_rule_for_x)==0){
train_data$`new_Y`[i]=0
}else if(Bayes_rule_for_x>=1/2){
train_data$'new_Y'[i]=1
}else{train_data$'new_Y'[i]=0}
}
sum(train_data$Y!=train_data$new_Y)/nrow(train_data)
#Calculate and Report the Bayes Risk
Bayes_Risk = sum(train_data$Y!=train_data$new_Y)/nrow(train_data)
Bayes_Risk
train_data_classifiers = as.factor(train_data$Y)
train_data_observations = data.frame(train_data$X)
knn.1 <-  knn(train_data_observations, train_data_observations, cl = train_data_classifiers, k=1)
R_knn_1 = 100 * sum(train_data_classifiers == knn.1)/length(knn.1)
R_knn_1
?knn
install.packages("class")
?knn
library(class)
knn
library(class)
train_data_classifiers = as.factor(train_data$Y)
train_data_observations = data.frame(train_data$X)
knn.1 <-  knn(train_data_observations, train_data_observations, cl = train_data_classifiers, k=1)
R_knn_1 = 100 * sum(train_data_classifiers == knn.1)/length(knn.1)
R_knn_1
knn.1
# Take special care to seperate the classifier from the rest of the data when fitting a
# knn model.  Consider the following code to give you an idea as to how one does this.
# Note, however, that this code is based off of my naming practices, and may require editing
# depending on your previous code.
library(class)
train_data_classifiers = as.factor(train_data$Y)
train_data_observations = data.frame(train_data$X)
#k=1
knn.1 <-  knn(train_data_observations, train_data_observations, cl = train_data_classifiers, k=1)
R_knn_1 = 100 * sum(train_data_classifiers == knn.1)/length(knn.1)
R_knn_1
#k=3
knn.3 <-  knn(train_data_observations, train_data_observations, cl = train_data_classifiers, k=3)
R_knn_3 = 100 * sum(train_data_classifiers == knn.3)/length(knn.3)
R_knn_3
#k=10
knn.10 <-  knn(train_data_observations, train_data_observations, cl = train_data_classifiers, k=10)
R_knn_10 = 100 * sum(train_data_classifiers == knn.10)/length(knn.10)
R_knn_10
library(MASS)
library(dplyr)
# Fit the model
model <- lda(Y~X, data = train_data)
# Make predictions
predictions <- model %>% predict(train_data)
?lda
lda(Y~X, data = train_data)
predict(train_data)
model %>% predict(train_data)
View(model)
View(model)
model$prior
model$counts
model$means
model
predictions$class
risk_predictions = sum(predictions$class!=train_data$Y)/length(train_data)
risk_predictions = sum(predictions$class!=train_data$Y)/length(train_data)
risk_predictions
W_obs = rnorm(150, mean = -2)
V_obs = rnorm(50, mean = 2)
Y_class_test = c(rep(0, times = length(W_obs)), rep(1, times = length(V_obs)))
test_data = data.frame(X = c(W_obs, V_obs), Y = Y_class_test)
##Calculate the Bayes Rule and Bayes Risk
#Construct a new column
test_data$'new_Y' = NA
#Compute Classifiers
for (i in 1:nrow(test_data)) {
x_obs = test_data[i,1]
#prob_x_given_0
given0_density = density(train_data$X[train_data$Y==0])
given0_index = sum(given0_density$x <= x_obs)
prob_x_given_0 = given0_density$y[given0_index]
#prob_x_given_1
given1_density = density(train_data$X[train_data$Y==1])
given1_index = sum(given1_density$x <= x_obs)
prob_x_given_1 = given1_density$y[given1_index]
Bayes_rule_for_x = prob_x_given_1 * pi_1 / (prob_x_given_1 * pi_1 + prob_x_given_0 * pi_0)
#Assign value to classifier
if(length(Bayes_rule_for_x)==0){
test_data$`new_Y`[i]=0
}else if(Bayes_rule_for_x>=1/2){
test_data$'new_Y'[i]=1
}else{test_data$'new_Y'[i]=0}
}
#Calculate and Report the Bayes' Risk
Bayes_Risk = sum(test_data$Y!=test_data$new_Y)/nrow(test_data)
Bayes_Risk
View(test_data)
# Take special care to seperate the classifier from the rest of the data when fitting a
# knn model.  Consider the following code to give you an idea as to how one does this.
# Note, however, that this code is based off of my naming practices, and may require editing
# depending on your previous code.
library(class)
train_data_classifiers = as.factor(train_data$Y)
train_data_observations = data.frame(train_data$X)
#k=1
knn.1 <-  knn(train_data_observations, train_data_observations, cl = train_data_classifiers, k=1)
R_knn_1 = 100 * sum(train_data_classifiers != knn.1)/length(knn.1)
R_knn_1
#k=3
knn.3 <-  knn(train_data_observations, train_data_observations, cl = train_data_classifiers, k=3)
R_knn_3 = 100 * sum(train_data_classifiers != knn.3)/length(knn.3)
R_knn_3
#k=10
knn.10 <-  knn(train_data_observations, train_data_observations, cl = train_data_classifiers, k=10)
R_knn_10 = 100 * sum(train_data_classifiers != knn.10)/length(knn.10)
R_knn_10
?knn
#knn risk
library(class)
train_data_classifiers = as.factor(train_data$Y)
train_data_observations = data.frame(train_data$X)
test_data_observations = data.frame(test_data$X)
#k=1
knn.1 <-  knn(train_data_observations, test_data_observations, cl = train_data_classifiers, k=1)
R_knn_1 = 100 * sum(train_data_classifiers != knn.1)/length(knn.1)
R_knn_1
#k=3
knn.3 <-  knn(train_data_observations, test_data_observations, cl = train_data_classifiers, k=3)
R_knn_3 = 100 * sum(test_data_classifiers != knn.3)/length(knn.3)
#knn risk
library(class)
train_data_classifiers = as.factor(train_data$Y)
train_data_observations = data.frame(train_data$X)
test_data_observations = data.frame(test_data$X)
#k=1
knn.1 <-  knn(train_data_observations, test_data_observations, cl = train_data_classifiers, k=1)
R_knn_1 = 100 * sum(train_data_classifiers != knn.1)/length(knn.1)
R_knn_1
#k=3
knn.3 <-  knn(train_data_observations, test_data_observations, cl = train_data_classifiers, k=3)
R_knn_3 = 100 * sum(train_data_classifiers != knn.3)/length(knn.3)
R_knn_3
#k=10
knn.10 <-  knn(train_data_observations, test_data_observations, cl = train_data_classifiers, k=10)
R_knn_10 = 100 * sum(train_data_classifiers != knn.10)/length(knn.10)
R_knn_10
#knn risk
library(class)
train_data_classifiers = as.factor(train_data$Y)
train_data_observations = data.frame(train_data$X)
test_data_observations = data.frame(test_data$X)
test_data_classifiers = as.factor(test_data$Y)
#k=1
knn.1 <-  knn(train_data_observations, test_data_observations, cl = train_data_classifiers, k=1)
R_knn_1 = 100 * sum(test_data_classifiers != knn.1)/length(knn.1)
R_knn_1
#k=3
knn.3 <-  knn(train_data_observations, test_data_observations, cl = train_data_classifiers, k=3)
R_knn_3 = 100 * sum(test_data_classifiers != knn.3)/length(knn.3)
R_knn_3
#k=10
knn.10 <-  knn(train_data_observations, test_data_observations, cl = train_data_classifiers, k=10)
R_knn_10 = 100 * sum(test_data_classifiers != knn.10)/length(knn.10)
R_knn_10
?lda
#LDA
library(MASS)
library(dplyr)
# Fit the model
model <- lda(Y~X, data = train_data)
# Make predictions
predictions <- model %>% predict(test_data)
#risk_predictions = sum(predictions$class!=train_data$Y)/length(train_data)
predictions$class
#LDA
library(MASS)
library(dplyr)
# Fit the model
model <- lda(Y~X, data = train_data)
# Make predictions
predictions <- model %>% predict(test_data)
risk_predictions = sum(predictions$class!=test_data$Y)/length(test_data)
risk_predictions
length(predictions$class)
predictions$class!=test_data$Y
sum(predictions$class!=test_data$Y)
length(test_data)
#LDA
library(MASS)
library(dplyr)
# Fit the model
model <- lda(Y~X, data = train_data)
# Make predictions
predictions <- model %>% predict(test_data)
risk_predictions = sum(predictions$class!=test_data$Y)/length(test_data$X)
length(test_data$X)
set.seed(13)
all_bayes_risks = c()
all_knn_risks = c()
all_lda_risks = c()
for(iteration in 1:1000){
W_obs = rnorm(150, mean = -2)
V_obs = rnorm(50, mean = 2)
Y_class_test = c(rep(0, times = length(W_obs)), rep(1, times = length(V_obs)))
test_data = data.frame(X = c(W_obs, V_obs), Y = Y_class_test)
##Calculate the Bayes Rule and Bayes Risk
#Construct a new column
test_data$'new_Y' = NA
#Compute Classifiers
for (i in 1:nrow(test_data)) {
x_obs = test_data[i,1]
#prob_x_given_0
given0_density = density(train_data$X[train_data$Y==0])
given0_index = sum(given0_density$x <= x_obs)
prob_x_given_0 = given0_density$y[given0_index]
#prob_x_given_1
given1_density = density(train_data$X[train_data$Y==1])
given1_index = sum(given1_density$x <= x_obs)
prob_x_given_1 = given1_density$y[given1_index]
Bayes_rule_for_x = prob_x_given_1 * pi_1 / (prob_x_given_1 * pi_1 + prob_x_given_0 * pi_0)
#Assign value to classifier
if(length(Bayes_rule_for_x)==0){
test_data$`new_Y`[i]=0
}else if(Bayes_rule_for_x>=1/2){
test_data$'new_Y'[i]=1
}else{test_data$'new_Y'[i]=0}
}
#knn risk
library(class)
train_data_classifiers = as.factor(train_data$Y)
train_data_observations = data.frame(train_data$X)
test_data_observations = data.frame(test_data$X)
test_data_classifiers = as.factor(test_data$Y)
#k=1
knn.1 <-  knn(train_data_observations, test_data_observations, cl = train_data_classifiers, k=1)
#LDA
library(MASS)
library(dplyr)
# Fit the model
model <- lda(Y~X, data = train_data)
# Make predictions
predictions <- model %>% predict(test_data)
bayes_risk = sum(test_data$Y!=test_data$new_Y)/nrow(test_data)
knn_risk = 100 * sum(test_data_classifiers != knn.1)/length(knn.1)
lda_risk = sum(predictions$class!=test_data$Y)/length(test_data$X)
all_bayes_risks = c(all_bayes_risks, bayes_risk)
all_knn_risks = c(all_knn_risks, knn_risk)
all_lda_risks = c(all_lda_risks, lda_risk)
}
set.seed(13)
all_bayes_risks = c()
all_knn_risks = c()
all_lda_risks = c()
for(iteration in 1:1000){
W_obs = rnorm(150, mean = -2)
V_obs = rnorm(50, mean = 2)
Y_class_test = c(rep(0, times = length(W_obs)), rep(1, times = length(V_obs)))
test_data = data.frame(X = c(W_obs, V_obs), Y = Y_class_test)
##Calculate the Bayes Rule and Bayes Risk
#Construct a new column
test_data$'new_Y' = NA
#Compute Classifiers
for (i in 1:nrow(test_data)) {
x_obs = test_data[i,1]
#prob_x_given_0
given0_density = density(train_data$X[train_data$Y==0])
given0_index = sum(given0_density$x <= x_obs)
prob_x_given_0 = given0_density$y[given0_index]
#prob_x_given_1
given1_density = density(train_data$X[train_data$Y==1])
given1_index = sum(given1_density$x <= x_obs)
prob_x_given_1 = given1_density$y[given1_index]
Bayes_rule_for_x = prob_x_given_1 * pi_1 / (prob_x_given_1 * pi_1 + prob_x_given_0 * pi_0)
#Assign value to classifier
if(length(Bayes_rule_for_x)==0){
test_data$`new_Y`[i]=0
}else if(Bayes_rule_for_x>=1/2){
test_data$'new_Y'[i]=1
}else{test_data$'new_Y'[i]=0}
}
#knn risk
library(class)
train_data_classifiers = as.factor(train_data$Y)
train_data_observations = data.frame(train_data$X)
test_data_observations = data.frame(test_data$X)
test_data_classifiers = as.factor(test_data$Y)
#k=1
knn.1 <-  knn(train_data_observations, test_data_observations, cl = train_data_classifiers, k=1)
#LDA
library(MASS)
library(dplyr)
# Fit the model
model <- lda(Y~X, data = train_data)
# Make predictions
predictions <- model %>% predict(test_data)
bayes_risk = sum(test_data$Y!=test_data$new_Y)/nrow(test_data)
knn_risk = sum(test_data_classifiers != knn.1)/length(knn.1)
lda_risk = sum(predictions$class!=test_data$Y)/length(test_data$X)
all_bayes_risks = c(all_bayes_risks, bayes_risk)
all_knn_risks = c(all_knn_risks, knn_risk)
all_lda_risks = c(all_lda_risks, lda_risk)
}
plot(all_bayes_risks)
all_bayes_risks
?plot
plot(all_bayes_risks)
plot(all_bayes_risks, col="red")
par(new=TRUE)
plot(all_knn_risks,col="green")
plot(all_bayes_risks, col="red")
par(new=TRUE)
plot(all_knn_risks,col="green")
plot(all_bayes_risks, col="red")
par(new=TRUE)
plot(all_knn_risks,col="green")
par(new=TRUE)
plot(all_lda_risks,col="blue")
?ggplot
a = cbind(as.matrix(c(1:1000)),as.matrix(all_bayes_risks),as.matrix(all_knn_risks),as.matrix(all_lda_risks))
View(a)
ggplot(a)
ggplot(as.data.frame(a))
a = as.data.frame(a)
a %>% ggplot() +
geom_point(aes(x = a$V1, y = total))
?ggplot
?plot
df = as.data.frame(cbind(as.matrix(c(1:1000)),as.matrix(all_bayes_risks),as.matrix(all_knn_risks),as.matrix(all_lda_risks)))
View(df)
df = as.data.frame(cbind(as.matrix(c(1:1000)),as.matrix(all_bayes_risks),as.matrix(all_knn_risks),as.matrix(all_lda_risks)))
ggplot(df, aes(V1)) +                    # basic graphical object
geom_line(aes(y=V2), colour="red") +   # first layer
geom_line(aes(y=V3), colour="green")+  # second layer
geom_line(aes(y=V4), colour="blue")    # Final layer
df = as.data.frame(cbind(as.matrix(c(1:1000)),as.matrix(all_bayes_risks),as.matrix(all_knn_risks),as.matrix(all_lda_risks)))
ggplot(df, aes(V1)) +                    # basic graphical object
geom_line(aes(y=V2), colour="red") +   # first layer
geom_line(aes(y=V3), colour="green")+  # second layer
geom_line(aes(y=V4), colour="blue")    # Final layer
df = as.data.frame(cbind(as.matrix(c(1:1000)),as.matrix(all_bayes_risks),as.matrix(all_knn_risks),as.matrix(all_lda_risks)))
ggplot(df, aes(V1)) +                    # basic graphical object
geom_line(aes(y=V2), colour="red") +   # first layer
geom_line(aes(y=V3), colour="green")+  # second layer
geom_line(aes(y=V4), colour="blue") +  # Final layer
ylab("Red-bayes, Green-knn, Blue-lda")+xlab("Index")
adult = read.csv("adults.csv")
adult$X = NULL
adult = read.csv("adults.csv")
adult$X = NULL
View(adult)
